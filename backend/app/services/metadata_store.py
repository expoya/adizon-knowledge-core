"""
MetadataService: Intelligenter Source Catalog Management (Phase 2.5)

Verwaltet alle verf√ºgbaren Datenquellen und findet die relevanten Sources
f√ºr eine gegebene User-Query.

Phase 2.5: LLM-basierte Source Discovery mit semantischem Verst√§ndnis.

Der Knowledge Graph ist die zentrale "Glue"-Schicht!
"""

import json
import logging
import os
from typing import Any, Dict, List, Optional
from pathlib import Path
import yaml

from langchain_core.messages import SystemMessage, HumanMessage
from app.core.llm import get_llm
from app.prompts import get_prompt

logger = logging.getLogger(__name__)


class SourceDefinition:
    """
    Repr√§sentiert eine Datenquelle aus dem Source Catalog.
    
    Eine Source kann sein:
    - knowledge_base: Vector Store + Knowledge Graph
    - CRM (Zoho CRM, Zoho Books)
    - SQL (IoT Datenbank, etc.)
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.id = config.get("id")
        self.type = config.get("type")  # vector_graph | crm | sql
        self.description = config.get("description", "")
        self.status = config.get("status", "active")
        self.tool = config.get("tool")  # Welches Tool wird aufgerufen?
        self.priority = config.get("priority", 99)
        self.requires_entity_id = config.get("requires_entity_id", False)
        self.capabilities = config.get("capabilities", [])
        self.keywords = config.get("keywords", [])
        self.modules = config.get("modules", [])
        self.tables = config.get("tables", [])
        self.connection_env = config.get("connection_env")
        self.note = config.get("note", "")
    
    def matches_query(self, query: str) -> float:
        """
        Berechnet Relevanz-Score f√ºr diese Source basierend auf Query.
        
        Args:
            query: User query (lowercase)
            
        Returns:
            float: 0.0 - 1.0 (Relevanz-Score)
        """
        query_lower = query.lower()
        score = 0.0
        max_score = 0.0
        
        # Check top-level keywords (0.3 pro Match)
        if self.keywords:
            max_score += 0.3
            for keyword in self.keywords:
                if keyword.lower() in query_lower:
                    score += 0.3
                    break  # Nur einmal z√§hlen
        
        # Check module keywords (0.4 pro Match)
        if self.modules:
            max_score += 0.4
            for module in self.modules:
                module_keywords = module.get("keywords", [])
                for keyword in module_keywords:
                    if keyword.lower() in query_lower:
                        score += 0.4
                        logger.debug(f"  Module '{module.get('name')}' matched: '{keyword}'")
                        break  # Nur ein Modul pro Source
                if score > max_score - 0.4:  # Modul gefunden
                    break
        
        # Check table keywords (0.4 pro Match, f√ºr SQL Sources)
        if self.tables:
            max_score += 0.4
            for table in self.tables:
                table_keywords = table.get("keywords", [])
                for keyword in table_keywords:
                    if keyword.lower() in query_lower:
                        score += 0.4
                        logger.debug(f"  Table '{table.get('name')}' matched: '{keyword}'")
                        break
                if score > max_score - 0.4:  # Tabelle gefunden
                    break
        
        # Normalize score to 0.0 - 1.0
        normalized_score = min(score / max(max_score, 0.01), 1.0) if max_score > 0 else 0.0
        
        return normalized_score
    
    def is_available(self) -> bool:
        """
        Pr√ºft ob die Source verf√ºgbar ist.
        
        Returns:
            bool: True wenn Source genutzt werden kann
        """
        if self.status == "active":
            return True
        elif self.status == "optional":
            # Check if connection is configured
            if self.connection_env:
                is_configured = bool(os.getenv(self.connection_env))
                if not is_configured:
                    logger.debug(f"Source {self.id} not available: {self.connection_env} not set")
                return is_configured
            return False
        else:
            logger.debug(f"Source {self.id} has status '{self.status}'")
            return False
    
    def get_relevant_modules(self, query: str) -> List[Dict[str, Any]]:
        """
        Findet relevante Module innerhalb dieser Source.
        
        Args:
            query: User query
            
        Returns:
            Liste von relevanten Modulen
        """
        query_lower = query.lower()
        relevant = []
        
        for module in self.modules:
            module_keywords = module.get("keywords", [])
            for keyword in module_keywords:
                if keyword.lower() in query_lower:
                    relevant.append(module)
                    break
        
        return relevant
    
    def get_relevant_tables(self, query: str) -> List[Dict[str, Any]]:
        """
        Findet relevante Tabellen innerhalb dieser Source (f√ºr SQL).
        
        Args:
            query: User query
            
        Returns:
            Liste von relevanten Tabellen
        """
        query_lower = query.lower()
        relevant = []
        
        for table in self.tables:
            table_keywords = table.get("keywords", [])
            for keyword in table_keywords:
                if keyword.lower() in query_lower:
                    relevant.append(table)
                    break
        
        return relevant
    
    def __repr__(self) -> str:
        return f"<SourceDefinition id={self.id} type={self.type} status={self.status}>"


class MetadataService:
    """
    Intelligenter Source Catalog (Phase 2).
    
    Entscheidet welche Datenquellen f√ºr eine Query relevant sind.
    Der Knowledge Graph wird IMMER zuerst abgefragt (als "Glue"-Schicht).
    """
    
    def __init__(self):
        self.sources: List[SourceDefinition] = []
        self.strategy: Dict[str, Any] = {}
        self._load_config()
    
    def _load_config(self) -> None:
        """L√§dt external_sources.yaml mit Source Catalog."""
        config_path = Path(__file__).parent.parent / "config" / "external_sources.yaml"
        
        if not config_path.exists():
            logger.warning(f"Source catalog not found: {config_path}")
            logger.warning("MetadataService will operate with empty catalog")
            return
        
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
                
                if not config:
                    logger.warning("Source catalog is empty")
                    return
                
                # Load sources
                for source_config in config.get("sources", []):
                    source = SourceDefinition(source_config)
                    self.sources.append(source)
                    logger.debug(f"Loaded source: {source.id} ({source.type})")
                
                # Load strategy
                self.strategy = config.get("selection_strategy", {})
            
            logger.info(f"‚úÖ Loaded {len(self.sources)} sources from catalog")
            
        except Exception as e:
            logger.error(f"Failed to load source catalog: {e}", exc_info=True)
    
    def get_relevant_sources(
        self, 
        query: str,
        min_score: float = None,
        max_sources: int = None
    ) -> List[SourceDefinition]:
        """
        Findet relevante Datenquellen f√ºr eine Query.
        
        Args:
            query: User query
            min_score: Minimum relevance score (default from strategy)
            max_sources: Maximum number of sources (default from strategy)
        
        Returns:
            List of relevant sources, sorted by priority and score
        """
        # Use defaults from strategy if not provided
        if min_score is None:
            min_score = self.strategy.get("min_relevance_score", 0.3)
        if max_sources is None:
            max_sources = self.strategy.get("max_parallel_sources", 3)
        
        scored_sources = []
        
        for source in self.sources:
            # Skip if not available
            if not source.is_available():
                logger.debug(f"  Source {source.id} not available, skipping")
                continue
            
            # Calculate relevance score
            score = source.matches_query(query)
            
            if score >= min_score:
                scored_sources.append((source, score))
                logger.debug(f"  ‚úì Source {source.id} matched with score {score:.2f}")
            else:
                logger.debug(f"  ‚úó Source {source.id} score {score:.2f} below threshold {min_score}")
        
        # Sort by priority (lower number = higher priority), then by score
        scored_sources.sort(key=lambda x: (x[0].priority, -x[1]))
        
        # Knowledge Graph immer dabei (wenn strategy sagt so) - VOR max_sources
        result = []
        if self.strategy.get("always_check_graph", True):
            kb_source = self.get_source_by_id("knowledge_base")
            if kb_source and kb_source.is_available():
                result.append(kb_source)
                logger.debug("  ‚ÑπÔ∏è Added knowledge_base (always check graph)")
        
        # Add other sources up to max_sources limit
        for source, score in scored_sources:
            if len(result) >= max_sources:
                break
            if source not in result:  # Skip if kb is already in result
                result.append(source)
        
        if result:
            logger.info(f"‚úÖ Selected {len(result)} sources: {[s.id for s in result]}")
        else:
            logger.warning("‚ö†Ô∏è No sources matched query, using default fallback")
            fallback = self.get_default_fallback()
            if fallback:
                result = [fallback]
        
        return result
    
    async def get_relevant_sources_llm(
        self, 
        query: str,
        max_sources: int = None,
        max_retries: int = 2
    ) -> List[SourceDefinition]:
        """
        LLM-basierte Source Discovery mit semantischem Verst√§ndnis (Phase 2.5).
        
        Der LLM analysiert die Query semantisch und w√§hlt passende Sources:
        - Versteht Synonyme ("Zahlungsstatus" ‚Üí Rechnungen)
        - Denkt in verwandten Begriffen
        - Gibt nicht auf bei fehlenden Matches
        - Zeigt Chain-of-Thought Reasoning
        
        Args:
            query: User query
            max_sources: Maximum number of sources (default from strategy)
            max_retries: Anzahl Retry-Versuche bei niedriger Confidence
        
        Returns:
            List of SourceDefinition (LLM-selected)
        """
        if max_sources is None:
            max_sources = self.strategy.get("max_parallel_sources", 3)
        
        logger.info("ü§ñ LLM-based Source Discovery (Phase 2.5)")
        
        for attempt in range(max_retries + 1):
            if attempt > 0:
                logger.info(f"  Retry attempt {attempt}/{max_retries}")
            
            try:
                # 1. Prepare Source Catalog f√ºr LLM
                catalog_description = self._format_catalog_for_llm()
                
                # 2. Load Prompt Template
                source_selection_prompt = get_prompt("source_selection")
                
                # 3. Format Prompt
                formatted_prompt = source_selection_prompt.format(
                    catalog=catalog_description,
                    query=query
                )
                
                # 4. Call LLM
                llm = get_llm(temperature=0.0, streaming=False)
                
                response = await llm.ainvoke([
                    SystemMessage(content="Du bist ein Source Selection Agent."),
                    HumanMessage(content=formatted_prompt)
                ])
                
                # 5. Parse Response (extract JSON from potential markdown)
                content = response.content.strip()
                
                # Remove markdown code blocks if present
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()
                
                # Clean control characters that break JSON parsing
                # Replace newlines, tabs, etc. within strings
                import re
                content = re.sub(r'[\x00-\x1F\x7F]', ' ', content)
                
                result = json.loads(content)
                
                reasoning = result.get("reasoning", "")
                source_ids = result.get("selected_sources", [])
                confidence = result.get("confidence", 0.0)
                alternative_terms = result.get("alternative_terms", [])
                
                # Log reasoning
                logger.info(f"  üí≠ LLM Reasoning: {reasoning[:200]}...")
                if alternative_terms:
                    logger.info(f"  üîç Alternative terms: {', '.join(alternative_terms)}")
                logger.info(f"  ‚úÖ Selected: {source_ids} (confidence: {confidence:.2f})")
                
                # 6. Get Source Objects
                selected_sources = []
                for source_id in source_ids:
                    source = self.get_source_by_id(source_id)
                    if source and source.is_available():
                        selected_sources.append(source)
                    else:
                        logger.warning(f"  ‚ö†Ô∏è Source '{source_id}' not found or not available")
                
                # 7. Ensure knowledge_base is included (always check graph strategy)
                if self.strategy.get("always_check_graph", True):
                    kb = self.get_source_by_id("knowledge_base")
                    if kb and kb.is_available():
                        if kb not in selected_sources:
                            selected_sources.insert(0, kb)
                            logger.debug("  ‚ÑπÔ∏è Added knowledge_base (always check graph)")
                
                # 8. Check if we have sources
                if selected_sources:
                    # Check confidence for retry
                    if confidence >= 0.7 or attempt >= max_retries:
                        return selected_sources[:max_sources]
                    else:
                        logger.warning(f"  ‚ö†Ô∏è Low confidence ({confidence:.2f}), retrying...")
                        continue
                else:
                    logger.warning("  ‚ö†Ô∏è No valid sources found, retrying...")
                    continue
                    
            except json.JSONDecodeError as e:
                logger.error(f"  ‚ùå Failed to parse LLM response: {e}")
                logger.debug(f"  Response was: {content[:500]}")
                
                if attempt >= max_retries:
                    logger.error("  ‚ùå All retries exhausted, falling back to keyword-based")
                    return self._fallback_keyword_based(query, max_sources)
                    
            except Exception as e:
                logger.error(f"  ‚ùå LLM Source Selection failed: {e}", exc_info=True)
                
                if attempt >= max_retries:
                    logger.error("  ‚ùå All retries exhausted, falling back to keyword-based")
                    return self._fallback_keyword_based(query, max_sources)
        
        # Final fallback
        logger.warning("‚ö†Ô∏è All retries exhausted, using fallback")
        return self._fallback_keyword_based(query, max_sources)
    
    def _format_catalog_for_llm(self) -> str:
        """
        Formatiert Source Catalog f√ºr LLM Context.
        
        Returns:
            Formatierter Catalog-String
        """
        lines = []
        
        for source in self.sources:
            if not source.is_available():
                continue
            
            lines.append(f"\n{'='*50}")
            lines.append(f"SOURCE: {source.id}")
            lines.append(f"{'='*50}")
            lines.append(f"Type: {source.type}")
            lines.append(f"Description: {source.description}")
            lines.append(f"Tool: {source.tool}")
            lines.append(f"Priority: {source.priority}")
            lines.append(f"Requires Entity ID from Graph: {source.requires_entity_id}")
            
            if source.keywords:
                # Limit keywords f√ºr Token-Effizienz
                keywords_sample = source.keywords[:15]
                lines.append(f"Keywords: {', '.join(keywords_sample)}")
                if len(source.keywords) > 15:
                    lines.append(f"  (... und {len(source.keywords) - 15} weitere)")
            
            if source.modules:
                lines.append("\nModules:")
                for module in source.modules[:6]:  # Max 6 Module
                    name = module.get("name", "")
                    entity_type = module.get("entity_type", "")
                    keywords = module.get("keywords", [])[:8]  # Max 8 Keywords pro Module
                    lines.append(f"  - {name} ({entity_type})")
                    lines.append(f"    Keywords: {', '.join(keywords)}")
            
            if source.tables:
                lines.append("\nTables:")
                for table in source.tables[:4]:  # Max 4 Tables
                    name = table.get("name", "")
                    desc = table.get("description", "")
                    keywords = table.get("keywords", [])[:8]
                    lines.append(f"  - {name}: {desc}")
                    lines.append(f"    Keywords: {', '.join(keywords)}")
            
            if source.capabilities:
                lines.append(f"\nCapabilities: {', '.join(source.capabilities)}")
            
            if source.note:
                lines.append(f"\nNote: {source.note}")
        
        return "\n".join(lines)
    
    def _fallback_keyword_based(
        self, 
        query: str, 
        max_sources: int = None
    ) -> List[SourceDefinition]:
        """
        Fallback zu keyword-based Source Selection.
        
        Args:
            query: User query
            max_sources: Maximum sources
            
        Returns:
            List of SourceDefinition
        """
        logger.info("üìã Fallback: Keyword-based source selection")
        
        # Use old keyword-based method
        if max_sources is None:
            max_sources = self.strategy.get("max_parallel_sources", 3)
        
        return self.get_relevant_sources(query, max_sources=max_sources)
    
    def get_source_by_id(self, source_id: str) -> Optional[SourceDefinition]:
        """
        Findet eine Source anhand ihrer ID.
        
        Args:
            source_id: Source ID
            
        Returns:
            SourceDefinition or None
        """
        for source in self.sources:
            if source.id == source_id:
                return source
        return None
    
    def should_combine_sources(self) -> bool:
        """
        Pr√ºft ob Quellen kombiniert werden sollen.
        
        Returns:
            bool: True wenn Multi-Source Queries erlaubt sind
        """
        return self.strategy.get("combine_sources", True)
    
    def get_default_fallback(self) -> Optional[SourceDefinition]:
        """
        Gibt die Default-Fallback-Source zur√ºck.
        
        Returns:
            SourceDefinition or None
        """
        fallback_id = self.strategy.get("default_fallback", "knowledge_base")
        return self.get_source_by_id(fallback_id)
    
    def requires_graph_first(self) -> bool:
        """
        Pr√ºft ob Graph immer zuerst abgefragt werden soll.
        
        Returns:
            bool: True wenn Graph immer zuerst kommt
        """
        return self.strategy.get("always_check_graph", True)
    
    def get_all_sources(self) -> List[SourceDefinition]:
        """
        Gibt alle konfigurierten Sources zur√ºck.
        
        Returns:
            Liste aller Sources
        """
        return self.sources
    
    def get_source_summary(self) -> str:
        """
        Erstellt eine Summary aller Sources (f√ºr Debugging).
        
        Returns:
            Formatierter String mit Source-Info
        """
        lines = ["=== Source Catalog Summary ==="]
        lines.append(f"Total Sources: {len(self.sources)}")
        lines.append("")
        
        for source in self.sources:
            available = "‚úÖ" if source.is_available() else "‚ùå"
            lines.append(f"{available} {source.id} ({source.type})")
            lines.append(f"   Priority: {source.priority}, Tool: {source.tool}")
            if source.requires_entity_id:
                lines.append(f"   Requires entity_id from Graph!")
            lines.append("")
        
        lines.append("Strategy:")
        lines.append(f"  - Always check graph: {self.strategy.get('always_check_graph')}")
        lines.append(f"  - Combine sources: {self.strategy.get('combine_sources')}")
        lines.append(f"  - Min score: {self.strategy.get('min_relevance_score')}")
        lines.append(f"  - Max sources: {self.strategy.get('max_parallel_sources')}")
        
        return "\n".join(lines)


# ==========================================
# Singleton Pattern
# ==========================================

_metadata_service_instance: Optional[MetadataService] = None

def metadata_service() -> MetadataService:
    """
    Returns singleton instance of MetadataService.
    
    Returns:
        MetadataService: The global metadata service instance
    """
    global _metadata_service_instance
    if _metadata_service_instance is None:
        _metadata_service_instance = MetadataService()
    return _metadata_service_instance


def reset_metadata_service() -> None:
    """
    Resets the singleton instance (f√ºr Tests).
    """
    global _metadata_service_instance
    _metadata_service_instance = None
