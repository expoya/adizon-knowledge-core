# LangSmith Tracing Setup

## Ãœbersicht

LangSmith ist das offizielle Tracing & Debugging Tool von LangChain. Es ermÃ¶glicht:
- âœ… Visualisierung der gesamten Agent-Chain
- âœ… Debugging von LLM-Calls und Tool-Aufrufen
- âœ… Performance-Monitoring
- âœ… Prompt-Testing und -Optimierung

---

## Setup (in 3 Minuten)

### 1. LangSmith Account erstellen

Gehe zu: [smith.langchain.com](https://smith.langchain.com)

- Registriere dich (kostenlos fÃ¼r Development)
- Erstelle ein neues Projekt (z.B. "adizon-knowledge-core")

### 2. API Key erhalten

In LangSmith Dashboard:
1. Gehe zu **Settings** â†’ **API Keys**
2. Klicke **Create API Key**
3. Kopiere den Key (z.B. `sk_lsv2_pt_...`)

### 3. Environment Variables setzen

FÃ¼ge diese 3 Variablen zu deiner `.env` Datei hinzu:

```bash
# LangSmith Tracing
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=adizon-knowledge-core
LANGCHAIN_API_KEY=sk_lsv2_pt_YOUR_KEY_HERE
```

**Docker/Railway:**  
FÃ¼ge die gleichen Variablen in die Railway Environment Variables ein.

### 4. Backend neu starten

```bash
# Lokal
cd backend
uvicorn app.main:app --reload

# Docker
docker-compose restart backend
```

---

## âœ… Verification

Nach dem Setup solltest du in den Logs sehen:

```
INFO:     Started server process [1]
INFO:     Application startup complete.
```

**In LangSmith:**  
Gehe zu [smith.langchain.com/projects](https://smith.langchain.com/projects)  
â†’ Ã–ffne dein Projekt  
â†’ Nach der ersten Query siehst du Traces!

---

## ðŸ“Š Was du sehen wirst

### Chain Visualization

```
User Query
  â†“
Router Node (LLM Classification)
  â”œâ”€ SQL Intent?
  â”‚   â†“
  â”‚   SQL Node
  â”‚   â”œâ”€ get_sql_schema Tool
  â”‚   â””â”€ execute_sql_query Tool
  â”‚
  â””â”€ Knowledge Intent?
      â†“
      Knowledge Node
      â””â”€ search_knowledge_base Tool
          â”œâ”€ Vector Search (PGVector)
          â””â”€ Graph Search (Neo4j)
```

### Debugging Information

Jeder Schritt zeigt:
- **Inputs:** Was kam rein?
- **Outputs:** Was kam raus?
- **Latency:** Wie lange dauerte es?
- **Tokens:** Wie viele Tokens wurden verwendet?
- **Errors:** Falls etwas schief ging

---

## ðŸ” Debugging Example

**Scenario:** Agent wÃ¤hlt SQL Tool statt Knowledge Tool

**In LangSmith:**
1. Ã–ffne die Trace der Query
2. Klicke auf "Router Node"
3. Sieh dir den Prompt an:
   ```
   INTENT TYPES:
   - "sql": Frage nach finanziellen Daten...
   - "knowledge": Frage nach CRM-Daten...
   ```
4. Sieh die LLM Response:
   ```
   sql  â† FALSCH!
   ```
5. **Erkenntniss:** Der Prompt muss klarer sein

**Fix:** Prompt anpassen in `chat_workflow.py` und neu testen.

---

## ðŸŽ¯ Use Cases

### 1. Router Debugging

**Problem:** Agent wÃ¤hlt falsches Tool

**LangSmith zeigt:**
- Welchen Prompt der Router bekam
- Wie der LLM klassifizierte
- Warum er sich fÃ¼r Tool X entschied

**Fix:** Prompt in `chat_workflow.py` verbessern

---

### 2. Tool Failure Debugging

**Problem:** Tool gibt Error zurÃ¼ck

**LangSmith zeigt:**
- Welche Parameter wurden Ã¼bergeben
- Was war die genaue Fehlermeldung
- Welche Tools danach aufgerufen wurden

**Fix:** Tool-Validierung verbessern

---

### 3. Performance Optimization

**Problem:** Agent ist langsam

**LangSmith zeigt:**
- Welcher Schritt dauert am lÃ¤ngsten
- Wie viele LLM Calls gemacht werden
- Ob unnÃ¶tige Tool-Calls existieren

**Fix:** Caching, parallele Calls, oder Prompt-Optimierung

---

## ðŸ› ï¸ Console Logging vs LangSmith

**Console Logging (aktuell aktiv):**
```
[ROUTER] User Query: Welche Kunden hatten einen Einwand?
[ROUTER] LLM Classification: 'knowledge' â†’ Intent: 'knowledge'
[ROUTER] âœ… Final Intent: 'knowledge'
[ROUTER] Next Node: knowledge_node
[KNOWLEDGE_NODE] ðŸ“š Executing Knowledge Node
[KNOWLEDGE_NODE] Tool: search_knowledge_base (Vector + Graph)
```

**LangSmith (zusÃ¤tzlich):**
- Visueller Graph der Chain
- Token Usage pro Schritt
- Latency Waterfall
- Complete Prompt & Response fÃ¼r jeden LLM Call
- Error Stacktraces

---

## ðŸ’¡ Best Practices

### 1. Separate Projekte fÃ¼r Environments

```bash
# Development
LANGCHAIN_PROJECT=adizon-dev

# Staging
LANGCHAIN_PROJECT=adizon-staging

# Production
LANGCHAIN_PROJECT=adizon-prod
```

### 2. Tagging wichtiger Queries

```python
# In Code (optional)
from langsmith import trace

@trace(tags=["important-customer", "debug"])
async def special_query(query: str):
    ...
```

### 3. Filter & Search

In LangSmith UI:
- Filter by: Status (success/error)
- Filter by: Latency (> 5s)
- Filter by: Tag
- Search: Specific query text

---

## ðŸš« Troubleshooting

### "No traces appearing"

**Check:**
1. `LANGCHAIN_TRACING_V2=true` (nicht "True" oder "1")
2. API Key ist korrekt (beginnt mit `sk_lsv2_pt_`)
3. Backend wurde neu gestartet
4. Firewall erlaubt Outbound zu `api.smith.langchain.com`

**Test:**
```bash
# In backend container/shell
python -c "import os; print(os.getenv('LANGCHAIN_TRACING_V2'))"
# Should print: true
```

### "Authentication Error"

**Check:**
- API Key in LangSmith regenerieren
- Neue Key in `.env` setzen
- Backend neu starten

### "Rate Limit Exceeded"

**Free Tier Limits:**
- 5,000 traces/month
- 50 MB storage

**LÃ¶sung:**
- Upgrade zu bezahltem Plan
- ODER: Tracing nur bei Bedarf aktivieren (ENV var Ã¤ndern)

---

## ðŸ“š Weitere Resources

- **LangSmith Docs:** [docs.smith.langchain.com](https://docs.smith.langchain.com)
- **Tutorial Video:** [LangSmith Tracing Basics](https://www.youtube.com/watch?v=...)
- **LangChain Discord:** Support Community

---

## ðŸŽ“ Quick Start Checklist

- [ ] Account bei smith.langchain.com erstellt
- [ ] API Key kopiert
- [ ] 3 ENV Vars in `.env` gesetzt
- [ ] Backend neu gestartet
- [ ] Test-Query im Chat gemacht
- [ ] Trace in LangSmith Dashboard sichtbar

**Wenn alle Checkboxen âœ… sind: Du bist bereit!** ðŸš€

---

**Status:** Ready for Production  
**Updated:** 2026-01-10

